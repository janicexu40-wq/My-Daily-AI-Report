#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç§äººæ·±åº¦æ™¨é—´æƒ…æŠ¥å®˜ - ä¸»ç¨‹åº
åŠŸèƒ½ï¼š
1. æ¯æ—¥è‡ªåŠ¨ç”Ÿæˆæ·±åº¦å•†ä¸šæƒ…æŠ¥æ’­å®¢
2. è‡ªåŠ¨æ¸…ç† Markdown æ ¼å¼ä»¥ä¼˜åŒ– TTS æœ—è¯»
3. Bark æ¨é€æ ¸å¿ƒæ‘˜è¦ + ç‚¹å‡»æŸ¥çœ‹å…¨æ–‡ (GitHubé“¾æ¥)
4. è‡ªåŠ¨æ¸…ç† 3 å¤©å‰çš„æ—§æ–‡ä»¶
"""

import os
import sys
import feedparser
import requests
from datetime import datetime, timedelta
import json
import asyncio
import time
import re
import glob
from typing import List, Dict

try:
    import edge_tts
except ImportError:
    print("æ­£åœ¨å®‰è£… edge-tts...")
    os.system("pip install edge-tts")
    import edge_tts

# ========== é…ç½®åŒº ==========
DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')
BARK_KEY = os.getenv('BARK_KEY')
# è·å– GitHub ä»“åº“å (æ ¼å¼: username/repo)ï¼Œå¦‚æœæœ¬åœ°æµ‹è¯•æ²¡æœ‰ç¯å¢ƒå˜é‡ï¼Œè¯·æ‰‹åŠ¨å¡« 'yourname/repo'
GITHUB_REPO = os.getenv('GITHUB_REPOSITORY', 'your-github-username/your-repo-name') 

# RSS æ–°é—»æº
RSS_SOURCES = [
    "https://rsshub.rssforever.com/infzm/2",              # å—æ–¹å‘¨æœ«
    "https://rsshub.rssforever.com/woshipm/popular/daily", # äººäººéƒ½æ˜¯äº§å“ç»ç†
    "https://www.huxiu.com/rss/0.xml",                    # è™å—… (å®˜æ–¹æº)
    "https://rsshub.rssforever.com/wallstreetcn/live/global/2", # åå°”è¡—è§é—»
    "https://rsshub.rssforever.com/cls/telegraph/red",          # è´¢è”ç¤¾
    "https://rsshub.rssforever.com/wallstreetcn/hot/day",       # åå°”è¡—çƒ­æ–‡
    "https://rsshub.rssforever.com/thepaper/channel/25950",     # æ¾æ¹ƒæ—¶äº‹
    "https://36kr.com/feed",                                    # 36Kr (å®˜æ–¹æº)
    "https://rsshub.rssforever.com/thepaper/channel/25951",     # æ¾æ¹ƒè´¢ç»
    "https://rsshub.rssforever.com/xueqiu/hots",                # é›ªçƒçƒ­å¸–
]

# è¾“å‡ºç›®å½•é…ç½®
OUTPUT_DIR = 'output'
DATE_STR = datetime.now().strftime('%Y%m%d')
AUDIO_FILE = f'{OUTPUT_DIR}/briefing_{DATE_STR}.mp3' 
TEXT_FILE = f'{OUTPUT_DIR}/briefing_{DATE_STR}.txt'
RSS_FILE = 'feed.xml'

# Edge-TTS è¯­éŸ³é…ç½®
VOICE_NAME = 'zh-CN-YunxiNeural'

# ========== å·¥å…·å‡½æ•° ==========

def clean_text_for_tts(text: str) -> str:
    """æ¸…ç† Markdown æ ¼å¼ç¬¦å·ï¼Œç¡®ä¿ TTS æœ—è¯»æµç•…"""
    text = re.sub(r'#+\s?', '', text)
    text = re.sub(r'\*\*|__|\*', '', text)
    text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
    text = re.sub(r'>\s?', '', text)
    text = re.sub(r'[-*]{3,}', '', text)
    text = re.sub(r'^\s*[-+]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'`{3}', '', text)
    return text.strip()

def cleanup_old_files(days_to_keep: int = 3):
    """åˆ é™¤ output ç›®å½•ä¸‹è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ä»¶"""
    print(f"ğŸ§¹ æ­£åœ¨æ¸…ç† {days_to_keep} å¤©å‰çš„æ—§æ–‡ä»¶...")
    now = time.time()
    cutoff = now - (days_to_keep * 86400)
    if not os.path.exists(OUTPUT_DIR): return
    
    files = glob.glob(os.path.join(OUTPUT_DIR, '*'))
    count = 0
    for f in files:
        if os.path.basename(f).startswith('.'): continue
        if os.path.getmtime(f) < cutoff:
            try:
                os.remove(f)
                count += 1
            except Exception: pass
    print(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {count} ä¸ªæ–‡ä»¶ã€‚\n")

def send_bark_notification(title: str, content: str, click_url: str = None):
    """é€šè¿‡ Bark å‘é€æ¨é€é€šçŸ¥ï¼Œæ”¯æŒç‚¹å‡»è·³è½¬"""
    if not BARK_KEY:
        print("âš ï¸  æœªé…ç½® BARK_KEYï¼Œè·³è¿‡æ¨é€é€šçŸ¥")
        return
    
    try:
        # 1. æˆªå–æ‘˜è¦ (ä¿ç•™å‰ 100 å­—ï¼Œç§»é™¤æ¢è¡Œä»¥é˜² URL æˆªæ–­)
        summary = content.replace('\n', ' ')[:100] + "..."
        
        # 2. æ„å»ºåŸºç¡€ URL
        # æ³¨æ„ï¼šBark çš„ URL ç»“æ„æ˜¯ /key/title/body
        url = f"https://api.day.app/{BARK_KEY}/{title}/{summary}"
        
        params = {
            'group': 'MorningBrief',
            'icon': 'https://cdn-icons-png.flaticon.com/512/2965/2965363.png'
        }
        
        # 3. å…³é”®ï¼šæ·»åŠ ç‚¹å‡»è·³è½¬é“¾æ¥
        if click_url:
            params['url'] = click_url
            
        requests.get(url, params=params, timeout=10)
        print(f"âœ… å·²å‘é€ Bark é€šçŸ¥ (å¸¦è·³è½¬é“¾æ¥): {title}")
    except Exception as e:
        print(f"âš ï¸  Bark æ¨é€å¤±è´¥: {e}")

def fetch_rss_articles() -> List[Dict]:
    """ä»å¤šä¸ª RSS æºæŠ“å–æ–°é—»"""
    articles = []
    now = datetime.now()
    cutoff_time = now - timedelta(hours=24)
    print(f"ğŸ“° å¼€å§‹ä» {len(RSS_SOURCES)} ä¸ªæºæŠ“å–æ–°é—»...")
    
    for source_url in RSS_SOURCES:
        try:
            feed = feedparser.parse(source_url, agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
            source_name = feed.feed.get('title', source_url)
            for entry in feed.entries[:15]:
                pub_time = None
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    pub_time = datetime(*entry.published_parsed[:6])
                if pub_time and pub_time < cutoff_time: continue
                
                articles.append({
                    'title': entry.title,
                    'summary': entry.get('summary', entry.get('description', ''))[:300],
                    'link': entry.link,
                    'source': source_name
                })
            print(f"  âœ“ {source_name}: è·å– {len([a for a in articles if a['source'] == source_name])} æ¡")
            time.sleep(1)
        except Exception as e:
            print(f"  âœ— æŠ“å–å¤±è´¥ {source_url}: {e}")
            
    print(f"ğŸ“Š å…±è·å– {len(articles)} æ¡æ–°é—»\n")
    return articles[:40]

def _call_dashscope(model: str, prompt: str, max_tokens: int, temperature: float, extra_params: dict = None) -> str:
    """åº•å±‚ API è°ƒç”¨"""
    if not DASHSCOPE_API_KEY: raise ValueError("æœªé…ç½® DASHSCOPE_API_KEY")
    
    url = 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions'
    headers = {'Authorization': f'Bearer {DASHSCOPE_API_KEY}', 'Content-Type': 'application/json'}
    system_prompt = 'ä½ æ˜¯ä¸€ä½èµ„æ·±è´¢ç»ç¼–è¾‘ã€‚è¾“å‡ºçº¯æ–‡æœ¬ï¼Œä¸ä½¿ç”¨ä»»ä½•Markdownæ ¼å¼ï¼ˆä¸ç”¨#ã€**ã€-ã€>ç­‰ç¬¦å·ï¼‰ï¼Œè¯­è¨€æµç•…è‡ªç„¶ï¼Œé€‚åˆæ’­å®¢æœ—è¯»ã€‚'
    
    payload = {
        'model': model,
        'messages': [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': prompt}],
        'max_tokens': max_tokens,
        'temperature': temperature
    }
    if extra_params: payload.update(extra_params)
    timeout = 300 if extra_params and extra_params.get('enable_thinking') else 60
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=timeout)
        response.raise_for_status()
        return response.json()['choices'][0]['message']['content']
    except Exception as e:
        print(f"âŒ API è°ƒç”¨å¤±è´¥ï¼ˆæ¨¡å‹: {model}ï¼‰: {e}")
        raise

def call_qwen_flash(prompt: str, max_tokens: int = 1000) -> str:
    print(f"  âš¡ è°ƒç”¨ qwen-flash...")
    return _call_dashscope(model='qwen-flash', prompt=prompt, max_tokens=max_tokens, temperature=0.7)

def call_qwen_max_thinking(prompt: str, max_tokens: int = 4000) -> str:
    thinking_budget = min(max_tokens * 2, 16000)
    print(f"  ğŸ§  è°ƒç”¨qwen-max (æ·±åº¦æ€è€ƒ)...")
    return _call_dashscope(
        model='qwen-max',
        prompt=prompt,
        max_tokens=max_tokens + thinking_budget,
        temperature=0.6,
        extra_params={'enable_thinking': True, 'thinking_budget': thinking_budget}
    )

def generate_section_a_overview(articles: List[Dict]) -> str:
    print("âœï¸  æ­£åœ¨ç”Ÿæˆã€æ¿å—Aã€‘...")
    news_text = "".join([f"{i+1}. {a['title']}\n   {a['summary'][:150]}\n\n" for i, a in enumerate(articles[:25])])
    prompt = f"è¯·åŸºäºä»¥ä¸‹æ–°é—»ç´ æï¼Œæ’°å†™ä¸€ä»½**2000å­—**çš„'å…¨çƒå•†ä¸šç§‘æŠ€ + ä¸­å›½æ°‘ç”ŸåŠ¨æ€'æ¦‚è§ˆã€‚\nã€é‡è¦ã€‘è¾“å‡ºçº¯æ–‡æœ¬ï¼Œä¸è¦ç”¨Markdownã€‚ä¸­å›½å†…å®¹å 50%ã€‚\næ–°é—»ç´ æï¼š\n{news_text}"
    return call_qwen_max_thinking(prompt, max_tokens=3000)

def generate_section_b_deep_dive(articles: List[Dict]) -> str:
    print("âœï¸  æ­£åœ¨ç”Ÿæˆã€æ¿å—Bã€‘...")
    titles = chr(10).join([f"{i+1}. {a['title']}" for i, a in enumerate(articles[:30])])
    selected_topics = call_qwen_flash(f"é€‰å‡º5-6ä¸ªæœ€å…·å•†ä¸šä»·å€¼çš„è¯é¢˜ï¼š\n{titles}", max_tokens=500)
    prompt = f"é’ˆå¯¹ä»¥ä¸‹è¯é¢˜è¿›è¡Œæ·±åº¦åˆ†æï¼ˆå…±5000å­—ï¼‰ï¼š\n{selected_topics}\nã€é‡è¦ã€‘è¾“å‡ºçº¯æ–‡æœ¬ï¼Œä¸è¦ç”¨Markdownã€‚åˆ†æé€»è¾‘ï¼šç°è±¡é€Ÿå†™ -> æœ¬è´¨æ‹†è§£ -> æé’±è·¯å¾„ -> é£é™©é¢„è­¦"
    return call_qwen_max_thinking(prompt, max_tokens=6000)

def assemble_full_script(section_a: str, section_b: str) -> str:
    date_str = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
    return f"æ¬¢è¿æ”¶å¬ç§äººæ™¨é—´æƒ…æŠ¥ï¼Œä»Šå¤©æ˜¯{date_str}ã€‚\n{section_a}\n\næ¥ä¸‹æ¥è¿›å…¥æ·±åº¦åˆ†ææ¿å—ã€‚\n{section_b}\n\næ„Ÿè°¢æ”¶å¬ã€‚"

async def generate_audio(text: str, output_path: str):
    print(f"ğŸ™ï¸  æ­£åœ¨ç”ŸæˆéŸ³é¢‘...")
    clean_text = clean_text_for_tts(text)
    communicate = edge_tts.Communicate(clean_text, voice=VOICE_NAME, rate='+5%')
    await communicate.save(output_path)

def generate_rss_feed(audio_url: str):
    print("ğŸ“¡ æ­£åœ¨ç”Ÿæˆ RSS Feed...")
    today = datetime.now().strftime('%Y-%m-%d')
    rss_content = f"""<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd">
  <channel>
    <title>ç§äººæ™¨é—´æƒ…æŠ¥</title>
    <item>
      <title>{today} æ™¨é—´æƒ…æŠ¥</title>
      <enclosure url="{audio_url}" type="audio/mpeg" length="100000"/>
      <guid>{today}</guid>
    </item>
  </channel>
</rss>"""
    with open(RSS_FILE, 'w', encoding='utf-8') as f:
        f.write(rss_content)

def main():
    print("ğŸš€ å¯åŠ¨...")
    try:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        articles = fetch_rss_articles()
        if not articles:
             print("âš ï¸ è­¦å‘Šï¼šæœªæŠ“å–åˆ°æ–°é—»ã€‚ä½¿ç”¨æµ‹è¯•æ•°æ®...")
             articles = [{'title': 'æµ‹è¯•æ–°é—»', 'summary': 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•', 'link': 'http://test', 'source': 'Test'}]

        if articles:
            section_a = generate_section_a_overview(articles)
            section_b = generate_section_b_deep_dive(articles)
            full_script = assemble_full_script(section_a, section_b)
            
            with open(TEXT_FILE, 'w', encoding='utf-8') as f:
                f.write(full_script)
            
            asyncio.run(generate_audio(full_script, AUDIO_FILE))
            
            # 5. æ›´æ–° RSS & Bark
            audio_filename = os.path.basename(AUDIO_FILE)
            text_filename = os.path.basename(TEXT_FILE)
            
            # ç”Ÿæˆ RSS é“¾æ¥ (Raw é“¾æ¥)
            rss_audio_url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main/{OUTPUT_DIR}/{audio_filename}"
            generate_rss_feed(rss_audio_url)
            
            # ç”Ÿæˆ å…¨æ–‡é˜…è¯»é“¾æ¥ (Blob é“¾æ¥ï¼Œé€‚åˆé˜…è¯»)
            full_text_url = f"https://github.com/{GITHUB_REPO}/blob/main/{OUTPUT_DIR}/{text_filename}"
            
            # å‘é€ Bark é€šçŸ¥ (ç‚¹å‡»è·³è½¬ GitHub)
            summary_candidate = clean_text_for_tts(section_a)[:100]
            send_bark_notification(
                f"{datetime.now().strftime('%mæœˆ%dæ—¥')}æ™¨é—´æƒ…æŠ¥", 
                summary_candidate,
                click_url=full_text_url
            )
            
            cleanup_old_files(days_to_keep=3)
            print("âœ… å…¨éƒ¨å®Œæˆ")
        else:
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == '__main__':
    main()
