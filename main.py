#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç§äººæ™¨é—´æƒ…æŠ¥å®˜ - GitHub Actions ç”Ÿäº§ç¯å¢ƒä¸“ç”¨ç‰ˆ
åŠŸèƒ½ï¼š
1. æŠ“å–å…¨ç½‘æ ¸å¿ƒå•†ä¸š/ç§‘æŠ€æ–°é—» (æ··åˆæºæŠ—åçˆ¬ç­–ç•¥)
2. "å•†ä¸šçŒæ‰‹"é£æ ¼æ·±åº¦æ‹†è§£ (ä¸¥æ ¼åŸºäºäº‹å®)
3. ç”Ÿæˆ .mp3 éŸ³é¢‘ + .html ç§»åŠ¨ç«¯ç½‘é¡µ
4. Bark æ¨é€ç½‘é¡µé“¾æ¥
"""

import os
import sys
import feedparser
import requests
from datetime import datetime, timedelta
import json
import asyncio
import time
import re
import glob
from typing import List, Dict, Tuple

# ========== è‡ªåŠ¨ä¾èµ–æ£€æŸ¥ä¸å®‰è£… ==========
try:
    import edge_tts
except ImportError:
    print("ğŸ“¦ æ­£åœ¨å®‰è£… edge-tts...")
    os.system("pip install edge-tts")
    import edge_tts

try:
    import markdown
except ImportError:
    print("ğŸ“¦ æ­£åœ¨å®‰è£… markdown...")
    os.system("pip install markdown")
    import markdown

# ========== å…¨å±€é…ç½®åŒº ==========
DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')
BARK_KEY = os.getenv('BARK_KEY')
GITHUB_REPO = os.getenv('GITHUB_REPOSITORY', 'yourname/yourrepo') 

# ğŸ”¥ ç»ˆæ RSS æºåˆ—è¡¨ (æ··åˆåŠ¨åŠ›ç‰ˆ - é€‚é… GitHub US èŠ‚ç‚¹)
# ç­–ç•¥ï¼šGitHub Actions ä½äºç¾å›½ï¼Œè®¿é—® rsshub.app é€šå¸¸é¡ºç•…ï¼Œ
# ä½†éƒ¨åˆ†æºç«™åçˆ¬ä¸¥æ ¼ï¼Œæ•…æ ¸å¿ƒæºä½¿ç”¨æŠ—å°é”èƒ½åŠ›å¼ºçš„é•œåƒã€‚
RSS_SOURCES = [
    # --- ç¬¬ä¸€æ¢¯é˜Ÿï¼šæ ¸å¿ƒè´¢ç» (ä½¿ç”¨é«˜å¯ç”¨é•œåƒ) ---
    "https://rsshub.rssforever.com/wallstreetcn/live/global/2",      # åå°”è¡—è§é—»-å¿«è®¯
    "https://rsshub.rssforever.com/wallstreetcn/hot/day",            # åå°”è¡—è§é—»-çƒ­æ¦œ
    "https://rsshub.rssforever.com/cls/telegraph/red",               # è´¢è”ç¤¾-ç”µæŠ¥
    "https://rsshub.rssforever.com/yicai/headline",                  # ç¬¬ä¸€è´¢ç»-å¤´æ¡
    
    # --- ç¬¬äºŒæ¢¯é˜Ÿï¼šæƒå¨å®˜åª’ (å®˜æ–¹æº + ä¼ªè£…å¤´) ---
    "https://rsshub.app/news/xhsxw",                      # æ–°åç¤¾
    "https://rsshub.app/thepaper/channel/25951",          # æ¾æ¹ƒ-è´¢ç»
    "https://rsshub.app/thepaper/channel/25950",          # æ¾æ¹ƒ-æ—¶äº‹
    
    # --- ç¬¬ä¸‰æ¢¯é˜Ÿï¼šæ·±åº¦ä¸ç§‘æŠ€ (æ··åˆç­–ç•¥) ---
    "https://rsshub.rssforever.com/36kr/newsflashes",     # 36Kr
    "https://rsshub.rssforever.com/sspai/index",          # å°‘æ•°æ´¾
    "https://rsshub.rssforever.com/woshipm/popular/daily",# äº§å“ç»ç†
    "https://rsshub.app/huxiu/channel/103",               # è™å—…
    
    # --- ç¬¬å››æ¢¯é˜Ÿï¼šç ”æŠ¥ ---
    "https://rsshub.rssforever.com/eastmoney/report/strategyreport", # ç­–ç•¥ç ”æŠ¥
]

# æ–‡ä»¶è·¯å¾„é…ç½®
OUTPUT_DIR = 'output'
DATE_STR = datetime.now().strftime('%Y%m%d')
AUDIO_FILENAME = f'briefing_{DATE_STR}.mp3'
AUDIO_FILE = f'{OUTPUT_DIR}/{AUDIO_FILENAME}'
MD_FILE = f'{OUTPUT_DIR}/briefing_{DATE_STR}.md'
HTML_FILE = f'{OUTPUT_DIR}/briefing_{DATE_STR}.html'
RSS_FILE = 'feed.xml'

VOICE_NAME = 'zh-CN-YunxiNeural'

# ========== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ==========

def clean_text_for_tts(text: str) -> str:
    """TTS æ–‡æœ¬æ¸…æ´—ï¼šç§»é™¤ Markdown ç¬¦å·ï¼Œä¿ç•™å¯è¯»å†…å®¹"""
    text = re.sub(r'#+\s?', '', text)              # å»æ ‡é¢˜
    text = re.sub(r'\*\*|__|\*', '', text)         # å»åŠ ç²—
    text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text) # å»é“¾æ¥ä¿ç•™æ–‡æœ¬
    text = re.sub(r'>\s?', '', text)               # å»å¼•ç”¨
    text = re.sub(r'[-*]{3,}', '', text)           # å»åˆ†å‰²çº¿
    text = re.sub(r'ğŸ“Š.*', '', text, flags=re.S)   # å»æ‰æœ«å°¾çš„ç»Ÿè®¡æ¨¡å—
    return text.strip()

def cleanup_old_files(days_to_keep: int = 3):
    """æ¸…ç†å†å²æ–‡ä»¶ï¼Œé˜²æ­¢ä»“åº“è†¨èƒ€"""
    print(f"ğŸ§¹ æ¸…ç† {days_to_keep} å¤©å‰çš„æ—§æ–‡ä»¶...")
    now = time.time()
    cutoff = now - (days_to_keep * 86400)
    if not os.path.exists(OUTPUT_DIR): return
    files = glob.glob(os.path.join(OUTPUT_DIR, '*'))
    for f in files:
        if os.path.basename(f).startswith('.'): continue
        if os.path.getmtime(f) < cutoff:
            try: os.remove(f)
            except: pass

def send_bark_notification(title: str, content: str, click_url: str = None):
    """å‘é€ Bark æ‰‹æœºæ¨é€"""
    if not BARK_KEY: return
    try:
        # æ‘˜è¦æˆªå–ï¼Œå»æ‰æ¢è¡Œ
        summary = content.replace('\n', ' ')[:100] + "..."
        url = f"https://api.day.app/{BARK_KEY}/{title}/{summary}"
        params = {
            'group': 'MorningBrief',
            'icon': 'https://cdn-icons-png.flaticon.com/512/2965/2965363.png'
        }
        if click_url: params['url'] = click_url
        requests.get(url, params=params, timeout=10)
        print(f"âœ… Bark æ¨é€æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ Bark æ¨é€å¤±è´¥: {e}")

def generate_html_file(markdown_text: str, output_path: str, audio_filename: str):
    """ç”Ÿæˆç§»åŠ¨ç«¯å‹å¥½çš„ HTML é¡µé¢"""
    print("ğŸ¨ æ­£åœ¨ç”Ÿæˆ HTML ç½‘é¡µ...")
    html_body = markdown.markdown(markdown_text)
    
    template = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
        <title>æ™¨é—´çŒæ‰‹å†…å‚</title>
        <style>
            body {{ font-family: -apple-system, BlinkMacSystemFont, "PingFang SC", "Helvetica Neue", Arial, sans-serif; background: #f7f7f7; color: #333; line-height: 1.75; margin: 0; padding: 0; }}
            .container {{ max-width: 650px; margin: 0 auto; background: #fff; padding: 20px 18px; min-height: 100vh; }}
            h1 {{ font-size: 22px; font-weight: bold; margin-bottom: 10px; line-height: 1.4; }}
            h2 {{ font-size: 18px; margin-top: 35px; border-left: 4px solid #d32f2f; padding-left: 10px; font-weight: 700; margin-bottom: 15px; }}
            h3 {{ font-size: 16px; font-weight: bold; margin-top: 20px; color: #444; }}
            p {{ margin-bottom: 16px; font-size: 16px; text-align: justify; }}
            strong {{ color: #d32f2f; font-weight: 700; }}
            ul {{ padding-left: 20px; }}
            li {{ margin-bottom: 8px; font-size: 16px; }}
            .audio-box {{ margin: 20px 0; padding: 15px; background: #f1f3f4; border-radius: 8px; text-align: center; }}
            audio {{ width: 100%; margin-top: 10px; outline: none; }}
            .meta {{ font-size: 14px; color: #888; margin-bottom: 20px; }}
            .footer {{ text-align: center; font-size: 12px; color: #ccc; margin-top: 50px; padding-bottom: 30px; }}
            hr {{ border: 0; border-top: 1px solid #eee; margin: 30px 0; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>â˜•ï¸ æ™¨é—´çŒæ‰‹å†…å‚ Â· æ·±åº¦å’–å•¡ç‰ˆ</h1>
            <div class="meta">{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')} | AI å•†ä¸šæƒ…æŠ¥</div>
            
            <div class="audio-box">
                <div style="font-weight:bold; color:#555; margin-bottom:5px;">ğŸ§ ç‚¹å‡»æ”¶å¬ä»Šæ—¥ç®€æŠ¥</div>
                <audio controls src="./{audio_filename}">æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘æ’­æ”¾ã€‚</audio>
            </div>
            
            {html_body}
            
            <div class="footer">Powered by AI Hunter & GitHub Actions</div>
        </div>
    </body>
    </html>
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(template)

# ========== æ ¸å¿ƒé€»è¾‘åŒº ==========

def fetch_rss_articles() -> Tuple[List[Dict], str]:
    """æŠ“å– RSS å¹¶è¿”å› (æ–‡ç« åˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯å­—ç¬¦ä¸²)"""
    articles = []
    stats = {}
    
    now = datetime.now()
    cutoff_time = now - timedelta(hours=25) 
    
    # ä¼ªè£…æˆ Chrome æµè§ˆå™¨ï¼Œè§£å†³å®˜æ–¹æºçš„åçˆ¬é™åˆ¶
    FAKE_HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8'
    }
    
    print(f"ğŸ“° æ­£åœ¨ä» {len(RSS_SOURCES)} ä¸ªæºæŠ“å–æ–°é—»...")
    
    for source_url in RSS_SOURCES:
        try:
            # ä½¿ç”¨ requests è·å–å†…å®¹ï¼Œå†ä¼ ç»™ feedparserï¼Œè¿™æ ·å¯ä»¥å®Œå…¨æ§åˆ¶ Headers
            resp = requests.get(source_url, headers=FAKE_HEADERS, timeout=15)
            if resp.status_code != 200:
                print(f"  âŒ {source_url}: HTTP {resp.status_code}")
                continue
                
            feed = feedparser.parse(resp.content)
            source_name = feed.feed.get('title', 'æœªçŸ¥æ¥æº').replace('RSSHub', '').replace(' - ', '').strip()
            
            count = 0
            for entry in feed.entries[:15]:
                # è§£ææ—¶é—´
                pub_time = None
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    pub_time = datetime(*entry.published_parsed[:6])
                
                # ç­›é€‰æœ€è¿‘25å°æ—¶
                if not pub_time or pub_time > cutoff_time:
                    articles.append({
                        'title': entry.title,
                        'summary': entry.get('summary', '')[:300], # æˆªå–æ‘˜è¦
                        'source': source_name
                    })
                    count += 1
            
            if count > 0:
                stats[source_name] = count
                print(f"  âœ… {source_name}: è·å– {count} æ¡")
            else:
                if feed.bozo:
                    print(f"  âš ï¸ {source_name}: è§£æå¼‚å¸¸ (å¯èƒ½è¢«æ‹¦æˆª)")
                else:
                    print(f"  âš ï¸ {source_name}: 0 æ¡æ›´æ–°")
                
        except Exception as e:
            print(f"  âŒ {source_url}: {e}")
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    if not stats:
        stats_str = "âš ï¸ æœ¬æ¬¡æœªä»ä»»ä½•æºæå–åˆ°æ–°é—»ï¼Œå¯èƒ½æ˜¯ç½‘ç»œæ³¢åŠ¨æˆ–æºç«™åçˆ¬ã€‚"
    else:
        stats_str = "\n".join([f"- {name}: {cnt}æ¡" for name, cnt in stats.items()])
    
    print(f"ğŸ“Š æ€»è®¡è·å– {len(articles)} æ¡æœ‰æ•ˆæ–°é—»")
    return articles[:60], stats_str

def _call_ai(prompt: str, max_tokens: int) -> str:
    """è°ƒç”¨ DashScope API ç”Ÿæˆå†…å®¹"""
    if not DASHSCOPE_API_KEY:
        return "âŒ é”™è¯¯ï¼šæœªé…ç½® DASHSCOPE_API_KEYï¼Œè¯·åœ¨ GitHub Secrets ä¸­è®¾ç½®ã€‚"
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä½ã€ä¸¥è°¨çš„å•†ä¸šæƒ…æŠ¥åˆ†æå¸ˆã€‘ã€‚
    
    **æ ¸å¿ƒåŸåˆ™**ï¼š
    1. **åŸºäºäº‹å®**ï¼šæ‰€æœ‰åˆ†æå¿…é¡»ä¸¥æ ¼åŸºäºç”¨æˆ·æä¾›çš„ã€æ–°é—»ç´ æã€‘ã€‚å¦‚æœä¸æ¸…æ¥šï¼Œè¯·å¿½ç•¥ï¼Œä¸¥ç¦ç¼–é€ ã€‚
    2. **ç¦æ­¢ç©¿è¶Š**ï¼šç´ æä¸­æœªæåŠæ—¥æœŸçš„ï¼Œé»˜è®¤æ˜¯â€œè¿‡å»24å°æ—¶â€ã€‚ä¸è¦ç¼–é€ æœªæ¥çš„æ—¥æœŸã€‚
    3. **æ ¼å¼è§„èŒƒ**ï¼šè¾“å‡ºæ ‡å‡†çš„ Markdown æ ¼å¼ã€‚
    """
    
    url = 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions'
    headers = {'Authorization': f'Bearer {DASHSCOPE_API_KEY}', 'Content-Type': 'application/json'}
    payload = {
        'model': 'qwen3-max',
        'messages': [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': prompt}],
        'max_tokens': max_tokens + 2000,
        'temperature': 0.2, # ä½æ¸©åº¦ï¼Œä¿è¯ factual correctness
        'enable_thinking': True,
        'thinking_budget': 1024
    }
    
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=300)
        resp_json = resp.json()
        if 'choices' in resp_json:
            return resp_json['choices'][0]['message']['content']
        else:
            print(f"AI Response Error: {resp_json}")
            return "AI ç”Ÿæˆè¿”å›æ ¼å¼å¼‚å¸¸"
    except Exception as e:
        print(f"AI Connection Error: {e}")
        return "AI ç”ŸæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨"

def generate_content(articles: List[Dict], stats_str: str) -> str:
    print("âœï¸  æ­£åœ¨ç”Ÿæˆæ–‡ç¨¿...")
    
    # === ç†”æ–­æœºåˆ¶ ===
    if not articles:
        return f"""
# æ™¨é—´çŒæ‰‹å†…å‚
**{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}**

---

## âš ï¸ ä»Šæ—¥æš‚åœæ›´æ–°

ç³»ç»Ÿåœ¨è¿‡å» 24 å°æ—¶å†…æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ–°é—»ä¿¡å·ã€‚
å¯èƒ½åŸå› ï¼š
1. èŠ‚å‡æ—¥æ–°é—»æºåœæ›´
2. ç½‘ç»œè¿æ¥å¼‚å¸¸
3. æ•°æ®æºåçˆ¬è™«ç­–ç•¥æ›´æ–°

### ğŸ“Š ç³»ç»Ÿè¯Šæ–­
{stats_str}
        """

    week_days = ["æ˜ŸæœŸä¸€", "æ˜ŸæœŸäºŒ", "æ˜ŸæœŸä¸‰", "æ˜ŸæœŸå››", "æ˜ŸæœŸäº”", "æ˜ŸæœŸå…­", "æ˜ŸæœŸæ—¥"]
    now = datetime.now()
    date_str = now.strftime('%Yå¹´%mæœˆ%dæ—¥')
    weekday_str = week_days[now.weekday()]
    
    news_pool = ""
    for i, a in enumerate(articles):
        news_pool += f"{i+1}. [{a['source']}] {a['title']}\næ‘˜è¦ï¼š{a['summary']}\n\n"
    
    prompt = f"""
    ä»Šå¤©æ˜¯{date_str}ï¼Œ{weekday_str}ã€‚
    è¯·ä»…åŸºäºä»¥ä¸‹ã€æ–°é—»ç´ æã€‘ï¼Œæ’°å†™ä¸€ä»½æ™¨é—´å†…å‚ã€‚
    
    **ç´ ææ± ï¼š**
    {news_pool}
    
    **å†™ä½œè¦æ±‚ï¼š**
    
    ## ç¬¬ä¸€éƒ¨åˆ†ï¼šå…¨æ™¯æ‰«æ
    ï¼ˆä»ç´ æä¸­ç²¾é€‰ 8-10 æ¡æœ‰ä»·å€¼çš„æ–°é—»ã€‚æ ¼å¼ï¼š"- **æ¥æº**ï¼šå…·ä½“å†…å®¹"ã€‚ï¼‰
    
    ## ç¬¬äºŒéƒ¨åˆ†ï¼šæ·±åº¦åˆ†æ
    ï¼ˆä»…å½“ç´ æä¸­æœ‰è¶³å¤Ÿä¿¡æ¯æ”¯æ’‘æ—¶ï¼Œé€‰å‡º 1-3 ä¸ªè¯é¢˜è¿›è¡Œæ‹†è§£ã€‚ï¼‰
    æ ¼å¼ï¼š
    ### è¯é¢˜ä¸€ï¼š[æ ‡é¢˜]
    1. **ç°çŠ¶**ï¼š(åŸºäºç´ æ)
    2. **çŒæ‰‹æ‹†è§£**ï¼š
       - **åˆ©ç›Šé“¾æ¡**ï¼š[è°åœ¨èµšé’±/äºé’±ï¼Ÿ]
       - **åº•å±‚é€»è¾‘**ï¼š[æ”¿ç­–æˆ–å•†ä¸šæœ¬è´¨]
    3. **æé’±è·¯å¾„**ï¼š
       - **çŸ­çº¿/ä¸­çº¿**ï¼š[æœºä¼šç‚¹]
    
    ---
    
    (æ–‡æœ«é™„ä¸Š)
    ### ğŸ“Š æœ¬æœŸæ•°æ®æºç»Ÿè®¡
    {stats_str}
    """
    
    return _call_ai(prompt, max_tokens=5000)

async def generate_audio(text: str, output_path: str):
    print(f"ğŸ™ï¸  æ­£åœ¨ç”ŸæˆéŸ³é¢‘...")
    clean_text = clean_text_for_tts(text)
    # ä½¿ç”¨ Edge TTSï¼ŒåŠ  5% è¯­é€Ÿ
    communicate = edge_tts.Communicate(clean_text, voice=VOICE_NAME, rate='+5%')
    await communicate.save(output_path)

def generate_rss(audio_url: str):
    today = datetime.now().strftime('%Y-%m-%d')
    content = f"""<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"><channel><title>æ™¨é—´çŒæ‰‹</title><item><title>{today}</title>
<enclosure url="{audio_url}" type="audio/mpeg" length="100000"/><guid>{today}</guid>
</item></channel></rss>"""
    with open(RSS_FILE, 'w') as f: f.write(content)

# ========== ä¸»ç¨‹åºå…¥å£ ==========

def main():
    print("ğŸš€ å¯åŠ¨ä»»åŠ¡ (GitHub Actions Mode)...")
    try:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # 1. æŠ“å– (å¸¦ç»Ÿè®¡)
        articles, stats_str = fetch_rss_articles()
        
        # 2. AI å†™ä½œ
        full_markdown = generate_content(articles, stats_str)
        
        # 3. ä¿å­˜ Markdown
        with open(MD_FILE, 'w', encoding='utf-8') as f:
            f.write(full_markdown)
            
        # 4. ç”Ÿæˆç½‘é¡µ
        generate_html_file(full_markdown, HTML_FILE, AUDIO_FILENAME)
        
        # 5. ç”ŸæˆéŸ³é¢‘
        asyncio.run(generate_audio(full_markdown, AUDIO_FILE))
        
        # 6. ç”Ÿæˆé“¾æ¥
        if '/' in GITHUB_REPO:
            username, repo_name = GITHUB_REPO.split('/')
            page_url = f"https://{username}.github.io/{repo_name}/{OUTPUT_DIR}/briefing_{DATE_STR}.html"
            rss_url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/main/{OUTPUT_DIR}/{AUDIO_FILENAME}"
        else:
            page_url = "https://github.com"
            rss_url = ""

        generate_rss(rss_url)
        
        # 7. Bark æ¨é€
        summary = clean_text_for_tts(full_markdown)[:60]
        if "æš‚åœæ›´æ–°" in full_markdown: summary = "ä»Šæ—¥æ— æœ‰æ•ˆæ–°é—»æå–"
        
        send_bark_notification(
            f"{datetime.now().strftime('%mæœˆ%dæ—¥')}æ™¨é—´çŒæ‰‹", 
            summary, 
            click_url=page_url
        )
        
        # 8. æ¸…ç†
        cleanup_old_files()
        print("âœ… ä»»åŠ¡å…¨éƒ¨å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ ä¸¥é‡é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()
